 Core Control‑Plane Primitives (from bedrock upward)

  - Identity & Trust Substrate – root keys and HSM/KMS, PKI, key rotation, secure bootstrap/attestation for nodes and workloads.
  - Authentication – pluggable auth providers (OIDC/SAML/JWT/mTLS), token issuance/validation, session lifetimes, device & workload
    identity.
  - Authorization / Policy Engine – ABAC/RBAC with a programmable policy language, PDP + PEPs, policy versioning, dry‑run and audit
    modes.
  - Secure Transport & Mesh – mTLS everywhere, certificate distribution, service discovery, zero‑trust segmentation, traffic identity
    propagation.
  - Secrets & Config Management – encrypted at rest/in flight, scoping and leases, rotation, change history, drift detection.
  - Audit & Immutable Ledger – append‑only event log with strong ordering, tamper evidence (hash chains/Merkle), time‑stamps, retention
    and query.
  - State & Metadata Store – authoritative resource registry (desired vs. observed state), schemas, migrations, optimistic concurrency,
    watch/notify.
  - Orchestration & Reconciliation Loop – controllers/operators that converge actual state to desired, idempotent actions, backoff,
    work queues.
  - Scheduling & Placement – capacity modeling, constraints/affinity, bin‑packing, preemption, quotas, fairness.
  - Policy‑Aware Admission Control – validate/mutate incoming requests/configs, guard rails for safety, deny/allow with reason.
  - Topology & Inventory – graph of services/nodes/endpoints, health, version, dependencies; supports impact analysis and rollout
    planning.
  - Change Management & Rollouts – versioned deployments, canary/blue‑green, feature flags, approvals, rollback checkpoints.
  - Observability Fabric – metrics/logs/traces/events unified, cardinality controls, SLOs/error budgets, anomaly alerts.
  - Data Plane Proxies/Sidecars – enforce authz, telemetry, rate limits, and routing near workloads; hot‑reload configs.
  - Rate Limiting & Quotas – token/leaky buckets, global + per‑tenant scopes, priority shedding.
  - Resilience Controls – circuit breakers, retries with jitter, timeouts, bulkheads, chaos hooks, dependency budgets.
  - Billing/Entitlement (if multi‑tenant) – metering at request/resource level, usage aggregation, entitlement checks.
  - Admin & Safety Rails – break‑glass access, scoped impersonation, dual control, sensitive action journaling.
  - Compliance & Data Governance – data classification tags, residency/retention policies, provenance, DLP hooks.
  - Interface Layer – declarative API/CRDs or GraphQL/REST, CLI/SDKs, schema evolution, strong typing, validation.

  Foundational stack (build order)

  1. Identity & Trust substrate
  2. Authn + Authz/Policy engine
  3. Secure transport/mesh
  4. Secrets/config mgmt
  5. Immutable audit/ledger
  6. State/metadata store
  7. Reconciliation/orchestration loop
  8. Admission control + policy‑aware mutations
  9. Scheduling/placement + topology inventory
  10. Data‑plane enforcement (proxies/sidecars)
  11. Observability fabric
  12. Change mgmt/rollouts + resilience controls
  13. Rate limiting/quotas + multi‑tenant billing
  14. Compliance/governance + admin safety rails
  15. Interface layer (APIs/SDK/CLI)

  This ordering lets you bootstrap trust, enforce policy, record every action, maintain desired state, then layer safety,
  observability, and customer‑facing interfaces.

Assessment (2026-02-02)
| # | Primitive | Status | Evidence |
|---|-----------|--------|----------|
| 1 | Identity & Trust substrate | ◐ | Signing + key handling (`lib/signing.py`, `lib/install_auth.py`, `lib/auth.py`); no attestation/KMS/rotation |
| 2 | Authentication | ◐ | HMAC tokens + passthrough (`lib/auth.py`); no OIDC/SAML/JWT or sessions |
| 3 | Authorization / Policy engine | ◐ | Static role map (`lib/authz.py`); no policy language/versioning or PDP/PEP split |
| 4 | Secure Transport & Mesh | ⚠️ | No TLS/mTLS or mesh/cert distribution code |
| 5 | Secrets & Config Management | ◐ | External secrets file handling (`lib/auth.py`), configs in `config/`; no vault/leases/rotation audit |
| 6 | Audit & Immutable Ledger | ✅ | Hash-chained ledger with Merkle verification (`lib/ledger_client.py`, `lib/merkle.py`, `scripts/ledger_repair.py`) |
| 7 | State & Metadata Store | ◐ | CSV registries + manifest integrity (`lib/registry.py`, `lib/integrity.py`, `registries/`); no transactional store/watch |
| 8 | Orchestration & Reconciliation Loop | ⚠️ | No controllers/work queues/idempotent reconcilers |
| 9 | Scheduling & Placement | ⚠️ | No scheduler/capacity/bin-packing; only plane topology (`lib/plane.py`) |
|10 | Policy-Aware Admission Control | ◐ | Gate enforcement for create/install/update (`lib/gate_operations.py`, `scripts/gate_check.py`); lacks policy language/mutators |
|11 | Topology & Inventory | ◐ | Plane topology/privilege model (`lib/plane.py`, `planes/*/tier.json`); no live inventory/health graph |
|12 | Change Mgmt & Rollouts (+ Resilience) | ◐ | Checkpoint/rollback scripts (`scripts/cp_version_checkpoint.py`, `cp_version_rollback.py`); no canary/blue-green/resilience patterns |
|13 | Observability Fabric | ⚠️ | No metrics/logs/traces/SLO handling |
|14 | Data Plane Proxies/Sidecars | ⚠️ | Not implemented |
|15 | Rate Limiting & Quotas (incl. Billing) | ⚠️ | Not implemented |
|16 | Compliance/Governance & Admin Safety Rails | ◐ | Pristine write guards (`lib/pristine.py`), governance frameworks; no dual control/break-glass flows |
|17 | Interface Layer (API/CLI/SDK) | ◐ | CLI scripts for packaging/install/integrity/ledger (`scripts/*`); no network API/SDK |

Upgrade Plan (2026-02-02)
- Foundations (Identity/Trust, Authn/Z, Transport): add KMS-backed key management and rotation; workload/node attestation; OIDC/JWT provider with refresh + device/workload IDs; PDP/PEP split with versioned policies and dry-run mode; mTLS bootstrap and cert distribution; tests for key rotation, OIDC integration, policy conformance.
- Secrets & Config: pluggable secrets backend (file/env → Vault/KMS), leases/TTLs and rotation hooks, drift detection, audited secret access; tests for lease expiry, rotation, drift alerts.
- Ledger/Audit: expand ledger coverage to all gate/security events; periodic Merkle checkpoints and remote verification; read API with pagination/filtering; tests for chain verification under rotation and tamper detection.
- State & Metadata Store: migrate registries to typed store (SQLite/Postgres) with migrations and CSV export; add optimistic concurrency and watch/notify; tests for concurrent updates, migrations, and watcher delivery.
- Orchestration/Reconciliation: controller loop with work queues/backoff; desired/observed CRDs; idempotent reconcilers for packages/registries/ledgers; tests for idempotency, retries, poison-message handling.
- Scheduling & Placement: constraint/bin-pack scheduler with quotas and preemption rules; capacity model; tests for placement correctness, quota enforcement, and preemption safety.
- Admission Control: policy-aware validators/mutators before gate operations; signed/versioned policy bundles; tests for allow/deny matrices, mutation safety, and policy regression.
- Topology & Inventory: live inventory graph with health/version; periodic discovery; impact analysis queries; tests for graph consistency, staleness thresholds, dependency walks.
- Change Mgmt & Rollouts + Resilience: canary/blue-green rollouts with automated abort; timeouts/retries/circuit breakers/bulkheads in controllers; tests for canary gates, rollback triggers, chaos scenarios.
- Observability Fabric: structured logs, metrics, traces with SLOs per primitive; alerting rules and error budgets; tests for emission, trace propagation, and alert thresholds.
- Data Plane Proxies/Sidecars: sidecar/proxy enforcing authz, rate limits, telemetry with hot-reload configs; tests for enforcement, reload safety, latency budgets.
- Rate Limiting & Billing: token-bucket service per tenant with usage metering and daily aggregation; entitlement checks; tests for rate accuracy, quota resets, billing edges.
- Compliance & Admin Safety Rails: dual control for sensitive actions; break-glass with ledgered justification; data classification tags enforced in policy; DLP hooks; tests for dual-control paths and classification propagation.
- Interface Layer: REST/GraphQL API with schema versioning and SDKs; request/response validation; CLI aligned to API; tests for contract compliance and backward compatibility.
- CI/CD & Governance: extend CI to run registry validator, contract/policy/resilience tests; sign artifacts and policy bundles; nightly chain-verify and drift detection; keep docs/templates in sync.
Feature Plans (100% targets)
- Foundations (Identity/Trust, Authn/Z, Transport): KMS plugin with rotation; attestation tokens; OIDC/JWT provider; PDP (Rego/Cedar) + PEP hooks in gate/sidecar; mTLS bootstrap + cert bundle installer. Tests: rotation, OIDC integration, PDP decisions, mTLS E2E.
  - Goal & Acceptance: mTLS-by-default, OIDC/JWT authn, PDP enforced at gates/sidecars, keys rotated, attestation present; all gate/sidecar calls authenticated; policies signed/versioned; mTLS tests green.
  - Dependencies: KMS/HSM or dev KMS; OIDC tenant; internal CA/cert bundle; policy engine runtime (Rego/Cedar); secrets paths; CI runners with OIDC/KMS access.
  - Design: `lib/kms.py`; `lib/attestation.py`; PDP service `lib/policy_pdp.py`; PEP hooks in gate/sidecar; cert bundle package via gate.
  - Steps: (1) KMS client + rotation job; (2) attestation issuer/validator; (3) OIDC/JWT provider with refresh; (4) embed PDP calls in gate + sidecar; (5) mTLS bootstrap/cert distro; (6) ledger events for key/policy actions.
  - Tests: unit (rotation, token validation), integration (OIDC login, PDP allow/deny), mTLS handshake E2E, policy regression.
  - Observability: PDP latency, auth failures, cert expiry; deny logs; traces through PDP.
  - Risks: IdP/KMS outages, clock skew, cert rollout risk; mitigations: cached bundles, staged rollout, feature flags.
  - DoD: tests green locally/CI; docs + sample config; ledgered rotations and policy signatures; rollback plan for cert/IdP change; CLI/sidecar use mTLS.

- Secrets & Config: driver interface (file/env/Vault), leases/TTLs, rotation scheduler, drift detector, read audit. Tests: lease expiry, rotation, drift alarm, denied reads.
  - Goal & Acceptance: secrets via drivers with leases/rotation; drift detection; every read audited; lease + rotation tests pass; drift alarms emitted; ledgered reads.
  - Dependencies: Vault/KMS backend, env/file fallback, rotation scheduler, alert channel.
  - Design: `lib/secrets/driver.py` (file/env/Vault); `lib/secrets/manager.py`; rotation job; drift comparator; audit sink to ledger.
  - Steps: driver interfaces; Vault backend; rotation job; drift detector; CLI `scripts/rotate_secrets.py`; ledger hooks.
  - Tests: lease TTL/renew/revoke, Vault integration, drift alarm, denied access.
  - Observability: metrics lease age, rotation success, drift count; denied-read logs; rotation alerts.
  - Risks: secret leakage, Vault downtime, stale caches; mitigations: redaction, retries/backoff, cache TTLs.
  - DoD: drivers implemented, alarms configured, docs + sample configs, CI Vault mock passing.

- Ledger/Audit: full event coverage; scheduled Merkle checkpoints + remote verifier; read/query API. Tests: chain verify across rotations, tamper injection, query filters.
  - Goal & Acceptance: all gate/security/reconciler events logged; checkpoints signed; remote verification; query API; chain-verify green after rotation; tamper test fails; paginated queries work.
  - Dependencies: storage for checkpoints (local/remote), signing keys, HTTP endpoint for queries.
  - Design: event map expansion; checkpoint scheduler; remote verifier; `lib/ledger_query.py` REST/CLI; signatures over checkpoints.
  - Steps: map events; implement checkpoint job; build verify command; add query API; document retention.
  - Tests: tamper injection, rotation + verify, query filters; perf smoke.
  - Observability: write latency, checkpoint lag, verification failures.
  - Risks: ledger growth, I/O contention, missing events; mitigations: batching, async, coverage audit.
  - DoD: coverage checklist done; verify job in CI; docs; size monitored.

- State & Metadata Store: migrate registries to SQLite/Postgres with migrations, CSV import/export, optimistic concurrency, watch/notify. Tests: concurrent writers, rollback, watch delivery.
  - Goal & Acceptance: typed store with OCC + watches; CSV round-trip preserved. Success = concurrent update tests pass; watchers deliver; CSV import/export lossless.
  - Dependencies: SQLite/Postgres, migration tool, notify channel (LISTEN/NOTIFY or queue).
  - Design: `lib/state_store.py`; migrations; CSV adapters; watch service.
  - Steps: define schemas; implement store + OCC; migrate registries; CSV CLI; watcher; update integrity checks.
  - Tests: OCC conflict, migration up/down, watch delivery, CSV fidelity.
  - Observability: conflict rates, watcher lag; migration logs.
  - Risks: dual-writes during migration, schema drift; mitigations: freeze window, backfill checksums.
  - DoD: store live; CI uses it; legacy CSV exported; integrity script green.

- Orchestration/Reconciliation: controller runtime with work queues/backoff; CRDs for packages/registries/ledgers; idempotent reconcilers. Tests: idempotency, retries, poison isolation.
  - Goal & Acceptance: controllers converge desired↔observed; idempotent with retries/backoff. Success = reconcilers pass idempotency + poison tests.
  - Dependencies: queue (Redis/NATS/SQS), persistence for work state, tracing.
  - Design: `lib/controller_runtime.py`; CRD schemas; reconcilers per resource; DLQ.
  - Steps: runtime skeleton; CRDs; package/registry/ledger reconcilers; DLQ; metrics hooks.
  - Tests: idempotency, retry jitter, DLQ path; integration with queue.
  - Observability: queue depth, success/fail rates, latency histograms.
  - Risks: thundering herd, poison loops; mitigations: jitter, DLQ, rate limits.
  - DoD: controllers run in CI/integration env; DLQ monitored; runbook ready.

- Scheduling & Placement: constraint/bin-pack scheduler with quotas/preemption and capacity model. Tests: placement correctness, quota enforcement, preemption safety.
  - Goal & Acceptance: feasible placements honoring constraints/quotas with safe preemption. Success = placement suite passes; quotas enforced.
  - Dependencies: capacity data, constraint schema, scheduling request channel.
  - Design: `lib/scheduler.py` scoring/bin-pack; quota module; preemption policy; admission hook.
  - Steps: constraint model; implement scoring; quota check; preemption; admission integration; CLI simulate.
  - Tests: constraint satisfaction, quota reject, preemption ordering, fairness.
  - Observability: placement latency, rejection reasons, preemption events.
  - Risks: starvation, bad capacity data; mitigations: aging, capacity refresh.
  - DoD: simulation tool; admission wired; docs/examples.

- Admission Control: pre-gate validator/mutator layer using signed, versioned policy bundles; dry-run channel. Tests: allow/deny matrix, mutation safety, policy regression.
  - Goal & Acceptance: create/install/update flows blocked without signed bundle; dry-run available; mutations safe. Success = policy regression green; unsigned bundle rejected.
  - Dependencies: policy signer keys, bundle registry, PDP service, gate hook.
  - Design: `lib/admission.py`; bundle schema + signatures; dry-run flag; mutation handlers; ledger logs.
  - Steps: bundle schema; signature verify; integrate with gate ops; add dry-run; sample mutations.
  - Tests: allow/deny tables, mutation invariants, version rollback, signature tamper.
  - Observability: denies per bundle version; mutation counts.
  - Risks: policy lockout, stale bundles; mitigations: canary rollout, cached last-good.
  - DoD: bundle signer in CI; gates enforce bundle; docs for authors.

- Topology & Inventory: live inventory graph (health/version); discovery job; impact queries. Tests: graph consistency, staleness, dependency walks.
  - Goal & Acceptance: current graph with health/version; impact queries accurate. Success = staleness thresholds met; dependency walks correct.
  - Dependencies: discovery endpoints, graph DB/store, health checks.
  - Design: `lib/inventory.py`; discovery agents; graph schema; query CLI.
  - Steps: graph model; discovery per resource; store + TTL; impact query endpoints.
  - Tests: graph consistency under churn, stale detection, impact correctness.
  - Observability: staleness metrics, discovery latency, missing nodes alerts.
  - Risks: incomplete discovery; mitigations: retries, fallbacks, manual overrides flagged.
  - DoD: scheduled discovery running; CLI query usable; dashboards live.

- Change Mgmt & Rollouts + Resilience: canary/blue-green with auto-abort; timeouts/retries/circuit breakers/bulkheads in controllers. Tests: canary gates, rollback triggers, chaos cases.
  - Goal & Acceptance: canary/blue-green with auto abort; controllers resilient. Success = chaos tests pass; rollback auto-triggers on SLO breach.
  - Dependencies: traffic router/feature flag, metrics signals, controller hooks.
  - Design: rollout controller; guardrails (timeouts, retries, CB, bulkheads); policy knobs.
  - Steps: rollout CRD; controller; SLO hook for abort; resilience middleware; sample flows.
  - Tests: canary pass/fail, rollback, timeout/CB behavior, chaos suite.
  - Observability: rollout progress metrics, abort reasons, resilience trips.
  - Risks: partial rollouts, noisy SLOs; mitigations: staged exposure, smoothing windows.
  - DoD: rollout controller demo in CI; resilience defaults on; runbook.

- Observability Fabric: structured logs/metrics/traces; SLOs per primitive; alerts/error budgets. Tests: emission, trace propagation, alert thresholds.
  - Goal & Acceptance: unified telemetry with SLOs/alerts. Success = signals emitted; alerts fire on breach.
  - Dependencies: telemetry backend (Prometheus/Loki/Tempo), exporters, alert channel.
  - Design: telemetry wrapper; SLO configs; alert rules; trace propagation.
  - Steps: add logging/metrics/traces hooks; define SLOs; ship alert rules; dashboards.
  - Tests: emit unit, trace propagation integration, alert threshold simulation.
  - Observability: dashboards, noise-tuned alerts.
  - Risks: cardinality, alert fatigue; mitigations: label budgets, rate limits, silence windows.
  - DoD: dashboards live; alerts tested; docs on signals.

- Data Plane Proxies/Sidecars: sidecar enforcing authz/rate/telemetry with hot-reload config; PDP integration. Tests: enforcement, reload safety, latency budget.
  - Goal & Acceptance: sidecar enforces authz/rate/telemetry with hot reload. Success = conformance tests; reload safe; latency within budget.
  - Dependencies: PDP endpoint, ratelimit service, certs, config distro.
  - Design: sidecar service; config watcher; filters (authz, rate, logging); PDP cache.
  - Steps: build sidecar; integrate PDP/ratelimit; hot-reload; package/distribute.
  - Tests: authz enforcement, rate accuracy, reload without drop, perf benchmark.
  - Observability: per-request metrics, reload events, cache hit rate.
  - Risks: perf regression, stale policies; mitigations: caching with TTL, perf gates.
  - DoD: sidecar image/package; sample deploy; CI conformance.

- Rate Limiting & Billing: token-bucket per tenant; usage metering + daily aggregation; entitlement checks. Tests: rate accuracy, quota reset, billing edges.
  - Goal & Acceptance: enforce per-tenant limits and meter usage; entitlement gates. Success = accuracy tests; billing edges handled.
  - Dependencies: counter store (Redis/DB), clock sync, billing sink.
  - Design: `lib/ratelimit.py` service; aggregator job; entitlement hook.
  - Steps: token bucket; integrate with admission/sidecar; metering pipeline; daily aggregation; export reports.
  - Tests: sustained load accuracy, reset timing, overage handling, entitlement deny.
  - Observability: bucket state, overage events, billing lag metrics.
  - Risks: counter drift, backend SPOF; mitigations: sharding, time sync, HA.
  - DoD: limits enforced; reports generated; docs/runbook.

- Compliance & Admin Safety Rails: dual-control for sensitive ops; break-glass with ledger justification; classification tags in policy; DLP hooks. Tests: dual-control paths, classification propagation.
  - Goal & Acceptance: sensitive ops need dual control; break-glass logged; data classified/enforced; DLP active. Success = dual-control tests pass; DLP block/allow per policy.
  - Dependencies: policy engine, ledger, identity roles, DLP scanner.
  - Design: approval workflow store; break-glass flagger; classification schema; DLP hook in sidecar/admission.
  - Steps: approval store; gate wiring; classification metadata; DLP checks; docs/runbooks.
  - Tests: dual-control accept/deny, break-glass logged, classification propagation, DLP block/allow.
  - Observability: alerts on break-glass, pending approvals, DLP hits.
  - Risks: approval latency, false positives; mitigations: SLAs, override path with audit.
  - DoD: dual-control enforced in CI/prod; DLP hook on; docs complete.

- Interface Layer: REST/GraphQL API with schema versioning; SDKs; request/response validation; CLI alignment; schema versioning. Tests: contract compliance, backward-compat matrix.
  - Goal & Acceptance: versioned API with SDKs and validated schemas; CLI aligned. Success = contract tests + compat matrix pass.
  - Dependencies: API runtime/gateway, schema registry, SDK tooling.
  - Design: OpenAPI/GraphQL schemas; server impl; SDK generators; CLI uses API; versioning policy.
  - Steps: draft schemas; handlers; validation middleware; generate SDKs; align CLI; version docs.
  - Tests: contract tests, compat matrix (vN vs vN-1), schema diff guard.
  - Observability: API latency/error metrics; schema version in logs.
  - Risks: breaking changes, generator drift; mitigations: semver, schema diff CI.
  - DoD: APIs deployed; SDKs published; CLI switched; compat suite green.

- CI/CD & Governance: CI stages (lint → registry validate → policy tests → contract/resilience tests → package/sign → chain-verify → drift check); signed policy/artifact bundles; nightly verify jobs. Tests: pipeline self-tests, signature verification, drift alerts.
  - Goal & Acceptance: CI enforces all gates/signatures; nightly verify/drift jobs. Success = required stages green; tamper/sig tests enforced.
  - Dependencies: CI runners with KMS/OIDC access, signing keys, artifact storage, test backends.
  - Design: pipeline definition with required stages; signing step; nightly jobs; reports.
  - Steps: update CI config; add registry validator; add policy/contract/resilience stages; signing + verify; drift detector; publish reports.
  - Tests: pipeline self-test (fails on missing stage), signature tamper test, drift injection.
  - Observability: pipeline dashboards, failure alerts, nightly status.
  - Risks: longer pipelines, flaky deps; mitigations: caching, retries, quarantine lane.
  - DoD: required stages locked; reports archived; nightly jobs running; contributor docs.

